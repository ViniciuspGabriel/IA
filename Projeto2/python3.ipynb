{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16738e0a",
   "metadata": {},
   "source": [
    "### Importação das bibliotecas que utilizaremos para trabalhar os dados e o arquivo chest_xray que contém as imagens para treinamento e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0419e0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importação das bibliotecas e imprimindo os arquivos que contém a pasta chest_xray\n",
    "import pandas as pd \n",
    "import cv2            \n",
    "import numpy as np         \n",
    "import os                  \n",
    "from random import shuffle\n",
    "from tqdm import tqdm  \n",
    "import scipy\n",
    "import skimage\n",
    "from skimage.transform import resize\n",
    "#from keras.utils.np_utils import to_categorical\n",
    "import tensorflow as tf\n",
    "print(os.listdir(\"/home/vinicius/Documentos/UTFPR/IA/projeto_ia/Inceptionv3_Pneumonia/chest_xray/chest_xray\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0ffcda0",
   "metadata": {},
   "source": [
    "### Imprimindo os arquivos que contém chest_xray/train, esse arquivo possui as imagens de treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be66136",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(os.listdir(\"/home/vinicius/Documentos/UTFPR/IA/projeto_ia/Inceptionv3_Pneumonia/chest_xray/chest_xray/train\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62b3cd80",
   "metadata": {},
   "source": [
    "### Selecionando as imagens dos diretórios de treinamento e teste, e separando as na proporção de 80% treinamento e 20% teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29a5b6cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "TRAIN_DIR = \"/home/vinicius/Documentos/UTFPR/IA/projeto_ia/Inceptionv3_Pneumonia/chest_xray/chest_xray/train\"\n",
    "TEST_DIR = \"/home/vinicius/Documentos/UTFPR/IA/projeto_ia/Inceptionv3_Pneumonia/chest_xray/chest_xray/test\"\n",
    "\n",
    "filenames = tf.io.gfile.glob(str(TRAIN_DIR))\n",
    "filenames.extend(tf.io.gfile.glob(str(TEST_DIR)))\n",
    "\n",
    "train_filenames, test_filenames = train_test_split(filenames, test_size=0.2)\n",
    "print(type(test_filenames))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bdbf452",
   "metadata": {},
   "source": [
    "### Função que buscar o rótulo(Normal ou PNEUMONIA) de cada imagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c4087b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(Dir):\n",
    "    X = []\n",
    "    y = []\n",
    "    for nextDir in os.listdir(Dir):\n",
    "        if not nextDir.startswith('.'):\n",
    "            if nextDir in ['NORMAL']:\n",
    "                label = 0\n",
    "            elif nextDir in ['PNEUMONIA']:\n",
    "                label = 1\n",
    "            else:\n",
    "                label = 2\n",
    "                \n",
    "            temp = Dir + '/' + nextDir\n",
    "            #tqdm mostra o progresso\n",
    "            for file in tqdm(os.listdir(temp)):\n",
    "                img = cv2.imread(temp + '/' + file)\n",
    "                if img is not None:\n",
    "                    img = skimage.transform.resize(img, (150, 150, 3))\n",
    "                    #img_file = scipy.misc.imresize(arr=img_file, size=(299, 299, 3))\n",
    "                    img = np.asarray(img)\n",
    "                    X.append(img)\n",
    "                    #print(X)\n",
    "                    y.append(label)\n",
    "                    #print(y)\n",
    "    X = np.asarray(X)\n",
    "    y = np.asarray(y)\n",
    "    return X,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99420225",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retorna as imagens de train em array\n",
    "train_filenames = \"\".join(map(str,train_filenames ))\n",
    "X_train, y_train = get_data(train_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c5059b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#retorna as imagens de teste em array\n",
    "test_filenames = \"\".join(map(str,test_filenames ))\n",
    "X_test , y_test = get_data(test_filenames)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013614d9",
   "metadata": {},
   "source": [
    "### Imprime a dimensão do DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97123895",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape,'\\n',X_test.shape)\n",
    "#X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f87b816b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_train.shape,'\\n',y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba1060c2",
   "metadata": {},
   "source": [
    "### Converte uma classe vetor em matrix de classe binaria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a35005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "#to_categorical, transforma a entrada em binario, 2 eh o numero de classe\n",
    "y_train = to_categorical(y_train, 2)\n",
    "y_test = to_categorical(y_test, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea78f7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Cria uma lista com o nome das imagens\n",
    "#listdir tras o nome de todos objetos contidos no diretorio\n",
    "Pimages = os.listdir(TRAIN_DIR + '/' + \"PNEUMONIA\")\n",
    "#print(Pimages)\n",
    "Nimages = os.listdir(TRAIN_DIR + '/' + \"NORMAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf850d50",
   "metadata": {},
   "source": [
    "### Plotando as imagens de Raio X de Não Pneumonia e Pneumonia dos pacientes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13d72cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "def plotter(i):\n",
    "    imagep1 = cv2.imread(TRAIN_DIR + '/PNEUMONIA/' + Pimages[i])\n",
    "    #print(imagep1)\n",
    "    imagep1 = skimage.transform.resize(imagep1, (150,150,3), mode = 'reflect')\n",
    "    imagen1 = cv2.imread(TRAIN_DIR + '/NORMAL/' + Nimages[i])\n",
    "    imagen1 = skimage.transform.resize(imagen1, (150,150,3), mode = 'reflect')\n",
    "    pair = np.concatenate((imagen1, imagep1), axis = 1)\n",
    "    print(\"(Left) - No Pneumonia Vs (Right) - Pneumonia\")\n",
    "    print(\"-----------------------------------------------------------------------------------------------------------------------------------\")\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.imshow(pair)\n",
    "    plt.show()\n",
    "for i in range(12,15):\n",
    "    plotter(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03f1bbcb",
   "metadata": {},
   "source": [
    "### Reduz a taxa de aprendizagem quando uma métrica para de melhorar, input da taxa de aprendizagem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f381015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ReduceLROnPlateau , ModelCheckpoint , LearningRateScheduler\n",
    "lr_reduce = ReduceLROnPlateau(monitor='val_acc', factor=0.001, epsilon=0.0001, patience=1, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b09b570b",
   "metadata": {},
   "source": [
    "### Chamada para salvar o modelo Keras ou pesos do modelo com alguma frequência no arquivo transferlearning_weights.hdf5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefdcda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath=\"transferlearning_weights.hdf5\"\n",
    "#save the model after every epoch\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea44e6af",
   "metadata": {},
   "source": [
    "### Importando biblioteca keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52480f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential , Model\n",
    "from keras.layers import Dense , Activation\n",
    "from keras.layers import Dropout , GlobalAveragePooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.constraints import maxnorm\n",
    "from keras.optimizers import SGD , RMSprop , Adadelta , Adam\n",
    "from keras.layers import Conv2D , BatchNormalization\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "#K.set_image_dim_ordering('th')\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.wrappers.scikit_learn import KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "731a2573",
   "metadata": {},
   "source": [
    "### Padronizando a dimensão do Dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "152f0839",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train=X_train.reshape(344,150,150,3)\n",
    "X_test=X_test.reshape(1390,150,150,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26f93802",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.shape(X_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42c1092d",
   "metadata": {},
   "source": [
    "### Importando InceptionV3 de Keras, com os pesos do imagenet (pré-treinamento)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dee34964",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "base_model = InceptionV3(weights='imagenet', include_top=False )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "209b5902",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.preprocessing import image\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, GlobalAveragePooling2D, GlobalMaxPooling2D\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "x = base_model.output\n",
    "x = Dropout(0.5)(x)\n",
    "\n",
    "x = GlobalMaxPooling2D()(x)\n",
    "\n",
    "x = Dense(128, activation='relu')(x)\n",
    "\n",
    "predictions = Dense(2, activation='sigmoid')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68ca96fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "model= Model(base_model.input,predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aaacee0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='binary_crossentropy',\n",
    "                  optimizer='adam', \n",
    "                  metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3d7836e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231aca4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "epochs = 500\n",
    "Learning_rate = 0.001\n",
    "Dropout = 0.5\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8316e6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x= X_train, y = y_train, validation_data = (X_test , y_test) ,callbacks=[lr_reduce,checkpoint] ,epochs = epochs,batch_size = batch_size)\n",
    "# fit(self, x, y, batch_size, nb_epoch, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch\n",
    "#history = model.fit(X_train, y_train,  (X_test , y_test) ,[lr_reduce,checkpoint] , epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f96dc0b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "465b5c83",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "pred = model.predict(X_test)\n",
    "pred = np.argmax(pred,axis = 1) \n",
    "y_true = np.argmax(y_test,axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bd92023",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(y_true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d7004d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CM = confusion_matrix(y_true, pred)\n",
    "from mlxtend.plotting import plot_confusion_matrix\n",
    "fig, ax = plot_confusion_matrix(conf_mat=CM ,  figsize=(5, 5))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161b6b00",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "print(confusion_matrix(y_true, pred))\n",
    "print(classification_report(y_true, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d87190e5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ceaeb52a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
